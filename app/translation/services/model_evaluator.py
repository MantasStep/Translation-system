# app/translation/services/model_evaluator.py

from typing import Dict, Tuple, List

# JÅ«sÅ³ esami importai BLEU ir BERT funkcijoms:
from app.translation.services.evaluation.bleu import compute_sentence_bleu
from app.translation.services.evaluation.bert import compute_bert_f1

# Naujas importas ChrF:
from app.translation.services.evaluation.chrf import compute_sentence_chrf


def filter_models_by_direction(
    hf_models: Dict[str, dict],
    src_lang: str,
    tgt_lang: str
) -> Dict[str, dict]:
    """
    GraÅ¾ina subset'Ä… hf_models, kurie palaiko tiksliai src_langâ†’tgt_lang kryptÄ¯.
    """
    from app.translation.constants import HF_MODELS

    active = {}
    print(f"ğŸ” [model_evaluator] Filtruojama reverse kryptis: {src_lang} â†’ {tgt_lang}")
    for key, info in hf_models.items():
        ax = HF_MODELS.get(key, {})
        dirs = ax.get("directions", [])
        for static_src, static_tgt in dirs:
            if static_src.split("_")[0] == src_lang and static_tgt.split("_")[0] == tgt_lang:
                active[key] = info
                break
    print(f"ğŸ” [model_evaluator] Atrinkti reverse modeliai: {list(active.keys())}")
    return active


def compute_back_translations(
    fwd_translation: str,
    reverse_models: Dict[str, dict],
    source_lang: str,
    target_lang: str
) -> List[str]:
    """
    Atlieka vienÄ… kartÄ… atgalinÄ¯ vertimÄ… (back-translation) fwd_translation per visus reverse_models.
    GrÄ…Å¾ina sÄ…raÅ¡Ä… atgaliniÅ³ tekstÅ³.
    """
    back_translations: List[str] = []
    print(f"ğŸ”„ [model_evaluator] Back-translation pradedama vienÄ… kartÄ…: '{fwd_translation[:30]}...'")

    for rev_name, rev_info in reverse_models.items():
        rev_tok = rev_info["tokenizer"]
        rev_model = rev_info["model"]
        print(f"ğŸ”„ [model_evaluator] Atgal verÄiama per modelÄ¯: {rev_name}")

        try:
            if rev_name.startswith("m2m100"):
                rev_tok.src_lang = target_lang
                encoded_bt = rev_tok(fwd_translation, return_tensors="pt")
                bos_id_bt = rev_tok.get_lang_id(source_lang)
                outs_bt = rev_model.generate(**encoded_bt, forced_bos_token_id=bos_id_bt)

            elif rev_name.startswith("mbart"):
                src_code_bt = f"{target_lang}_XX" if target_lang != "lt" else "lt_LT"
                tgt_code_bt = f"{source_lang}_XX" if source_lang != "lt" else "lt_LT"
                rev_tok.src_lang = src_code_bt
                encoded_bt = rev_tok(fwd_translation, return_tensors="pt")
                try:
                    bos_id_bt = rev_tok.lang_code_to_id[tgt_code_bt]
                except KeyError:
                    print(f"âš ï¸ [model_evaluator] Modelis '{rev_name}' nepalaiko '{tgt_code_bt}', praleidÅ¾iu.")
                    continue
                outs_bt = rev_model.generate(**encoded_bt, forced_bos_token_id=bos_id_bt)

            else:
                encoded_bt = rev_tok(fwd_translation, return_tensors="pt", padding=True)
                outs_bt = rev_model.generate(**encoded_bt)

        except Exception as exc:
            print(f"âš ï¸ [model_evaluator] Klaida vertime '{rev_name}': {exc}. PraleidÅ¾iu Å¡Ä¯ modelÄ¯.")
            continue

        back_text = rev_tok.batch_decode(outs_bt, skip_special_tokens=True)[0]
        print(f"ğŸ”„ [model_evaluator] Back-text: '{back_text[:30]}...'")
        back_translations.append(back_text)

    if not back_translations:
        print("âš ï¸ [model_evaluator] NÄ—ra reverse modeliÅ³ arba nepavyko versti atgal, grÄ…Å¾inu tuÅ¡ÄiÄ… sÄ…raÅ¡Ä….")
    return back_translations


def round_trip_bleu_per_candidate(
    back_translations: List[str],
    source_text: str
) -> float:
    """
    Paimus jau apskaiÄiuotus atgalinius vertimus (back_translations), grÄ…Å¾ina vidutinÄ¯ BLEU.
    Jei back_translations sÄ…raÅ¡as tuÅ¡Äias, graÅ¾ina 0.0.
    """
    if not back_translations:
        print("âš ï¸ [model_evaluator][BLEU] NÄ—ra atgaliniÅ³ tekstÅ³, grÄ…Å¾inu BLEU=0")
        return 0.0

    total_bleu = 0.0
    for bt in back_translations:
        bleu = compute_sentence_bleu(bt, source_text)
        print(f"ğŸ“ [model_evaluator] BLEU bt vs source: {bleu:.2f}")
        total_bleu += bleu

    avg_bleu = total_bleu / len(back_translations)
    print(f"ğŸ“Š [model_evaluator] Vidutinis BLEU uÅ¾ kandidatÄ…: {avg_bleu:.2f}")
    return avg_bleu


def round_trip_bert_per_candidate(
    back_translations: List[str],
    source_text: str,
    source_lang: str
) -> float:
    """
    Paimus jau apskaiÄiuotus back_translations, grÄ…Å¾ina vidutinÄ¯ BERTScore F1.
    Jei back_translations sÄ…raÅ¡as tuÅ¡Äias arba BERTScore dalis meta klaidÄ…, graÅ¾ina 0.0.
    """
    if not back_translations:
        print("âš ï¸ [model_evaluator][BERT] NÄ—ra atgaliniÅ³ tekstÅ³, grÄ…Å¾inu BERTScore=0")
        return 0.0

    try:
        hypotheses = back_translations
        references = [source_text] * len(back_translations)
        f1_scores = compute_bert_f1(hypotheses, references, lang=source_lang)
    except Exception as e:
        print(f"âš ï¸ [model_evaluator][BERT] BERTScore skaiÄiavimo klaida: {e}. GrÄ…Å¾inu 0.0")
        return 0.0

    for idx, f1 in enumerate(f1_scores):
        print(f"ğŸ“ [model_evaluator] BERTScore (F1) bt vs source (model {idx}): {f1:.4f}")

    avg_f1 = sum(f1_scores) / len(f1_scores)
    print(f"ğŸ“Š [model_evaluator] Vidutinis BERT F1 uÅ¾ kandidatÄ…: {avg_f1:.4f}")
    return avg_f1


def select_best_by_round_trip(
    candidates: Dict[str, str],
    hf_models: Dict[str, dict],
    source_text: str,
    source_lang: str,
    target_lang: str
) -> Tuple[str, str]:
    """
    (BLEU-vien tik pasirinkimas)
    IÅ¡ candidates pasirenka geriausiÄ… vertimÄ… pagal round-trip BLEU,
    bet atgalinÄ¯ vertimÄ… atlieka tik vienÄ… kartÄ… per kandidatÄ….
    """
    print(f"ğŸ” [model_evaluator] Pradedama geriausio modelio paieÅ¡ka pagal BLEU...")
    reverse_models = filter_models_by_direction(hf_models, target_lang, source_lang)

    if not reverse_models:
        best_model_name = max(candidates, key=lambda m: len(candidates[m]))
        print(f"âš ï¸ [model_evaluator] Reverse modeliÅ³ nÄ—ra, pasirenkamas ilgiausias: {best_model_name}")
        return candidates[best_model_name], best_model_name

    bleu_scores: Dict[str, float] = {}
    for fwd_model_name, fwd_translation in candidates.items():
        print(f"ğŸ” [model_evaluator] SkaiÄiuoju BLEU uÅ¾ kandidatÄ…: {fwd_model_name}")

        back_texts = compute_back_translations(
            fwd_translation, reverse_models, source_lang, target_lang
        )

        avg_bleu = round_trip_bleu_per_candidate(back_texts, source_text)
        bleu_scores[fwd_model_name] = avg_bleu

    best_model_name = max(bleu_scores, key=bleu_scores.get)
    print(f"ğŸ† [model_evaluator] Geriausias BLEU modelis: {best_model_name} (BLEU={bleu_scores[best_model_name]:.2f})")
    return candidates[best_model_name], best_model_name


def select_best_by_hybrid(
    candidates: Dict[str, str],
    hf_models: Dict[str, dict],
    source_text: str,
    source_lang: str,
    target_lang: str,
    weight_bleu: float = 0.5
) -> Tuple[str, str]:
    """
    IÅ¡ candidates pasirenka geriausiÄ… vertimÄ…,
    kombinuodama round-trip BLEU, BERTScore F1 ir ChrF.
    AtgalinÄ¯ vertimÄ… atlieka tik vienÄ… kartÄ… per kandidatÄ….
    """
    print(f"ğŸ” [model_evaluator] Pradedama hibridinio geriausio modelio paieÅ¡ka (BLEU+BERT+ChrF)...")
    reverse_models = filter_models_by_direction(hf_models, target_lang, source_lang)

    if not reverse_models:
        best_model_name = max(candidates, key=lambda m: len(candidates[m]))
        print(f"âš ï¸ [model_evaluator] Reverse modeliÅ³ nÄ—ra, pasirenkamas ilgiausias: {best_model_name}")
        return candidates[best_model_name], best_model_name

    scores_hybrid: Dict[str, float] = {}
    bleu_scores: Dict[str, float] = {}
    bert_scores: Dict[str, float] = {}
    chrf_scores: Dict[str, float] = {}

    for mdl_name, fwd_translation in candidates.items():
        print(f"ğŸ” [model_evaluator] SkaiÄiuoju BLEU, BERT ir ChrF uÅ¾ kandidatÄ…: {mdl_name}")

        # 1) Atlieku vienÄ… back-translation visiems reverse modeliams:
        back_texts = compute_back_translations(
            fwd_translation, reverse_models, source_lang, target_lang
        )

        # 2) Vidutinis BLEU:
        avg_bleu = round_trip_bleu_per_candidate(back_texts, source_text)
        bleu_scores[mdl_name] = avg_bleu

        # 3) Vidutinis BERTScore F1:
        avg_f1 = round_trip_bert_per_candidate(back_texts, source_text, source_lang)
        bert_scores[mdl_name] = avg_f1

        # 4) Vidutinis ChrF:
        total_chrf = 0.0
        for bt in back_texts:
            chrf_val = compute_sentence_chrf(bt, source_text)
            print(f"ğŸ“ [model_evaluator] ChrF bt vs source: {chrf_val:.2f}")
            total_chrf += chrf_val
        avg_chrf = total_chrf / len(back_texts) if back_texts else 0.0
        print(f"ğŸ“Š [model_evaluator] Vidutinis ChrF uÅ¾ kandidatÄ…: {avg_chrf:.2f}")
        chrf_scores[mdl_name] = avg_chrf

        # 5) Hibridinis balas (pvz., BLEU 50%, BERT 30%, ChrF 20%):
        weight_bert = 0.3
        weight_chrf = 0.2
        hybrid_score = (
            weight_bleu * avg_bleu +
            weight_bert * (avg_f1 * 100) +
            weight_chrf * avg_chrf
        )
        scores_hybrid[mdl_name] = hybrid_score

        print(
            f"ğŸ”¢ [model_evaluator] Modelis {mdl_name}: "
            f"BLEU={avg_bleu:.2f}, BERT_F1={avg_f1:.4f}, ChrF={avg_chrf:.2f}, "
            f"HIBRID={hybrid_score:.2f}"
        )

    best_model_name = max(scores_hybrid, key=scores_hybrid.get)
    print(
        f"ğŸ† [model_evaluator] Hibridinis geriausias modelis: {best_model_name} "
        f"(HIBRID={scores_hybrid[best_model_name]:.2f})"
    )
    return candidates[best_model_name], best_model_name
